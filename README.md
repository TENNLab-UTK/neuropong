# Neuropong
This is the repo contains the NeuroPong project files. NeuroPong is an embedded, neuromorphic Atari (Pong) agent. It marries an event-based camera, TENNLab's Neuromorphic Starter Kit, and an Atari 2600 console. Spiking neural networks are trained on simulated events created from frames generated by the Arcade Learning Environment, and then, those spiking neural networks are put on hardware to examine how they perform in a live setting using real event camera inputs.

## Prerequisites
Repositories needed to run existing spiking neural network agents:

- TENNLab Embedded Neuromorphic repository(*):
    - Needed to compile code for Neuromorphic Starter Kit's Raspberry Pi Picos
- Inivation `dv-processing` Library: https://gitlab.com/inivation/dv/dv-processing

(*) You will need to get access to this repo **IN ADDITION TO** the actual agent spiking neural network(s) from Jim Plank (jplank@utk.edu).

You will also need Python and a shell of some kind (bash/zsh) on Linux or Mac. It is recommended to set up a python virtual environment (Python <= 3.9) for compatability with Inivation event camera library.

## Contents

- **/models**: STL models of 3D printed objects used in this project for the presented prototype

- **/kit-code**: Contains code used by `embedded-neuromorphic/` repo to compile kit code.

- **/pcb**: Repo containing KiCad files for the PCB that contains the Atari Translator circuit

- **/scripts**: Scripts used to assist with flashing Picos and compiling kit code. `calibration.py` and `event_server.py` are used on the Raspberry Pi (or whatever is communicating with the Neuromorphic Starter Kit)

- **/imgs**: Contains various diagrams and images detailing parts of the NeuroPong system

## Table of Hardware Materials/Components


## Running the System

1. Turn on monitor, put VideoOlympics cartridge in Atari 2600 console, and turn on the Atari console.
    - You should see the Pong game appear on the screen.
2. Plug NeuroPong controller into the back of one of the Atari controller ports.
3. Power on the Neuromorphic Kit and Raspberry Pi, and plug DAVIS346 camera into one of the USB ports on the Raspberry Pi.
4. Compile the network using `app_compile` from the `embedded_neuromorphic/` repo
    - Ex: `./bin/app_compile -j network_file -o kit-code/pico-pong_observations.c -a kit-code/pico-pong_actions[2,3].c -s`
5. Flash the three Raspberry Pi Picos on the kit with the appropriate encoder, decoder, and network. 
6. On the Raspberry Pi, run `scripts/calibration.py` to assist with focusing the lens and cropping the camera's FOV to the screen.
    - The output produced by `scripts/calibration.py` is the command that is used to run `scripts/event_server.py`.
        - It figures out what the crop coordinates are and what the downsampling parameters need to be to match whatever the target downsampled resolution is. Target resolution is specified via global variables in the `scripts/calibration.py` program.
7. Run the command output by `scripts/calibration.py`
    - Ex: `python3 event_server.py --crop ...`
8. Wait 20-30 seconds for the system to initialize. If it's unreponsive, CTRL-C the event_server process and rerun it.
9. Begin the Atari game by toggling the ``Game Reset'' switch on the Atari system.
     


## TODO
1. Test amended calibration.py and event_server.py. 
    - Should I also add the C++ downsampling code too? Or just the Python version (which will be slower.)
2. From `../2024-neuropong-sd/docs`:
    - Bryson, I'm leaning toward excluding `kit_overview.md`. I'm not sure it's necessary, and I'm afraid and explanations will be outdated by the time the open-source version is released. What do you think?
3. Bryson, can you double check if anything needs to be ripped out of the 3 files in `kit-code`? Does anything in these files need to be better reflected in the paper? 

